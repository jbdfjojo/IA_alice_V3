import os
import json
import time
import pyttsx3
import speech_recognition as sr
from PyQt5.QtCore import (
    Qt, QThread, pyqtSignal, QMutex, QThreadPool, QRunnable
)
from PyQt5.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QTextEdit, QLabel,
    QCheckBox, QComboBox, QScrollArea, QApplication
)
from PyQt5.QtGui import QPixmap, QTextCursor

from llama_cpp_agent import LlamaCppAgent
from gui.memory_window import MemoryViewer



# Thread reconnaissance vocale
class VoiceRecognitionThread(QThread):
    result_signal = pyqtSignal(str)

    def __init__(self, agent):
        super().__init__()
        self.agent = agent
        self.running = True
        self.is_paused = False
        self.is_processing_response = False
        self.mutex = QMutex()
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone(device_index=1)
        self.last_active_time = time.time()
        self.max_inactive_duration = 30  # secondes

        print("Microphones disponibles :")
        for i, name in enumerate(sr.Microphone.list_microphone_names()):
            print(f"{i}: {name}")


    def run(self):
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source, duration=1)
            while self.running:
                # Blocage dur pendant la pause
                if self.is_paused:
                    print("üé§ Micro en pause (thread bloqu√©)")
                    time.sleep(0.5)
                    continue

                try:
                    print("üé§ En √©coute...")
                    audio = self.recognizer.listen(source, timeout=10)
                    if self.is_paused:  # s√©curit√© suppl√©mentaire apr√®s l'√©coute
                        print("üîá Micro d√©sactiv√© pendant l'√©coute. Abandon du traitement.")
                        continue

                    print("üîä Traitement audio...")
                    text = self.recognizer.recognize_google(audio, language="fr-FR").lower()
                    self.last_active_time = time.time()
                    print(f"[DEBUG] Texte reconnu brut : '{text}'")

                    if "alice" in text:
                        print("[DEBUG] Mot-cl√© 'alice' d√©tect√©")
                        cleaned_text = text.split("alice", 1)[-1].strip()
                        if cleaned_text:
                            self.is_processing_response = True
                            self.result_signal.emit(cleaned_text)
                        else:
                            print("‚ö†Ô∏è Mot-cl√© d√©tect√©, mais rien apr√®s.")
                    else:
                        print("üîá Aucun mot-cl√© d√©tect√© dans :", text)

                except sr.WaitTimeoutError:
                    print("‚è±Ô∏è Aucun son d√©tect√©.")
                except sr.UnknownValueError:
                    print("ü§∑ Audio incompr√©hensible")
                except sr.RequestError as e:
                    print(f"‚ùå Erreur API : {e}")
                finally:
                    self.is_processing_response = False


    def pause(self):
        self.is_paused = True
        print("üîá Micro mis en pause (is_paused = True)")

    def resume(self):
        self.is_paused = False
        self.last_active_time = time.time()
        print("üé§ Micro repris (is_paused = False)")


    def stop(self):
        self.running = False
        self.quit()
        self.wait()


# Ex√©cuter une fonction dans un thread sans bloquer l'UI
class RunnableFunc(QRunnable):
    def __init__(self, func):
        super().__init__()
        self.func = func

    def run(self):
        self.func()


# Fonction utilitaire
def load_config():
    config_path = "config.json"
    if os.path.exists(config_path):
        with open(config_path, "r") as file:
            try:
                return json.load(file)
            except json.JSONDecodeError as e:
                print(f"[ERREUR CONFIG] : {e}")
    return {}


def save_config(config):
    with open("config.json", "w") as file:
        json.dump(config, file, indent=4)


# Interface principale
class MainWindow(QWidget):
    def __init__(self, model_paths: dict, agent):
        super().__init__()
        self.setWindowTitle("Alice - Interface IA")
        self.setGeometry(100, 100, 800, 600)

        self.model_paths = model_paths
        self.agent = agent
        self.config = load_config()

        self.voice_input_enabled = False
        self.voice_recognition_thread = VoiceRecognitionThread(self.agent)
        self.voice_recognition_thread.result_signal.connect(self.on_text_recognized)
        self.voice_recognition_thread.start()

        self.is_user_speaking = True

        self.setup_ui()

        # Restaurer le mod√®le pr√©c√©dent
        last_model = self.config.get("last_model", "Mistral-7B-Instruct")
        index = self.model_selector.findText(last_model)
        self.model_selector.setCurrentIndex(index if index != -1 else 0)
        self.voice_checkbox.setChecked(self.config.get("voice_enabled", True))

    def setup_ui(self):
        layout = QVBoxLayout()
        control_layout = QHBoxLayout()

        self.voice_checkbox = QCheckBox("Voix")
        self.voice_checkbox.stateChanged.connect(self.toggle_voice)

        self.memory_button = QPushButton("M√©moire")
        self.memory_button.clicked.connect(self.open_memory_window)

        self.model_selector = QComboBox()
        self.model_selector.addItems(self.model_paths.keys())
        self.model_selector.currentTextChanged.connect(self.load_model)

        self.voice_button = QPushButton("üé§ Micro: OFF")
        self.voice_button.setCheckable(True)
        self.voice_button.clicked.connect(self.toggle_voice_input)
        self.voice_button.setStyleSheet("background-color: lightcoral; font-weight: bold;")

        control_layout.addWidget(self.voice_checkbox)
        control_layout.addWidget(self.memory_button)
        control_layout.addWidget(self.model_selector)
        control_layout.addWidget(self.voice_button)

        layout.addLayout(control_layout)

        self.response_box = QTextEdit()
        self.response_box.setReadOnly(True)
        layout.addWidget(self.response_box)

        self.waiting_label = QLabel("Alice r√©fl√©chit...")
        self.waiting_label.setAlignment(Qt.AlignCenter)
        self.waiting_label.setVisible(False)
        layout.addWidget(self.waiting_label)

        self.input_box = QTextEdit()
        self.input_box.setPlaceholderText("Entrez votre message ici...")
        layout.addWidget(self.input_box)

        button_layout = QHBoxLayout()
        self.send_button = QPushButton("Envoyer")
        self.send_button.clicked.connect(self.send_prompt)
        self.save_button = QPushButton("Sauvegarder")
        self.save_button.clicked.connect(self.save_prompt)
        button_layout.addWidget(self.send_button)
        button_layout.addWidget(self.save_button)

        layout.addLayout(button_layout)

        self.image_label = QLabel()
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidget(self.image_label)
        self.scroll_area.setVisible(False)
        layout.addWidget(self.scroll_area)

        self.setLayout(layout)

    def toggle_voice(self, state):
        self.config["voice_enabled"] = bool(state)
        save_config(self.config)

    def toggle_voice_input(self):
        self.voice_input_enabled = not self.voice_input_enabled

        if self.voice_input_enabled:
            self.voice_button.setText("üé§ Micro: ON")
            self.voice_button.setStyleSheet("background-color: lightgreen; font-weight: bold;")
            self.voice_recognition_thread.resume()
            print("üé§ Micro activ√© par bouton")
        else:
            self.voice_button.setText("üé§ Micro: OFF")
            self.voice_button.setStyleSheet("background-color: lightcoral; font-weight: bold;")
            self.voice_recognition_thread.pause()
            print("üîá Micro d√©sactiv√© par bouton")

    def load_model(self, model_name):
        self.config["last_model"] = model_name
        save_config(self.config)

        try:
            self.agent = LlamaCppAgent(self.model_paths, selected_model=model_name)
            print(f"‚úÖ Mod√®le charg√© : {model_name}")
            self.voice_recognition_thread.agent = self.agent  # Update agent dans le thread
        except Exception as e:
            print(f"[ERREUR CHARGEMENT MOD√àLE] : {e}")

    def on_text_recognized(self, text):
        if self.is_user_speaking:
            self.response_box.append(f"[Vous] {text}")
            self.input_box.setText(text)
            self.is_user_speaking = False

            self.voice_recognition_thread.pause()

            if "image" in text.lower():
                self.generate_image_from_text(text)
            elif "code" in text.lower():
                self.generate_code_from_text(text)
            else:
                self.generate_model_response(text)

    def generate_model_response(self, prompt):
        self.waiting_label.setVisible(True)
        QApplication.processEvents()

        def run():
            response = self.agent.generate(prompt)
            self.response_box.append(f"[Alice] {response}")
            self.waiting_label.setVisible(False)

            if self.voice_checkbox.isChecked():
                self.agent.speak(response)

            self.is_user_speaking = True
            self.voice_recognition_thread.resume()

        QThreadPool.globalInstance().start(RunnableFunc(run))

    def generate_image_from_text(self, text):
        self.response_box.append(f"<b>[Vous]</b> {text}")
        self.response_box.append("<b>[Alice]</b> Je vais g√©n√©rer une image... Veuillez patienter ‚è≥")
        QApplication.processEvents()

        def run():
            result = self.agent.generate_image(text)
            image_path = None

            if "#image" in result:
                image_path = result.split("#image")[-1].strip()
                self.response_box.append("<b>[Alice]</b> Voici votre image :")
            else:
                self.response_box.append(f"<b>[Alice]</b> {result}")
                self.voice_recognition_thread.resume()
                return

            import time, os
            time.sleep(1)
            image_path = os.path.normpath(image_path)

            if os.path.exists(image_path):
                from PyQt5.QtGui import QPixmap
                pixmap = QPixmap(image_path)
                if not pixmap.isNull():
                    # ‚úÖ Int√©grer directement l‚Äôimage redimensionn√©e dans la conversation
                    img_html = f'<img src="{image_path}" width="350">'
                    self.response_box.append(img_html)
                    print("[DEBUG] Image ins√©r√©e dans la conversation.")
                else:
                    self.response_box.append("<b>[Alice]</b> ‚ö†Ô∏è L‚Äôimage n‚Äôa pas pu √™tre charg√©e.")
            else:
                self.response_box.append("<b>[Alice]</b> ‚ö†Ô∏è Fichier image introuvable.")

            self.voice_recognition_thread.resume()

        QThreadPool.globalInstance().start(RunnableFunc(run))

    def generate_code_from_text(self, text):
        self.response_box.append("[Code] (fonction √† impl√©menter)")

    def send_prompt(self):
        prompt = self.input_box.toPlainText().strip()
        if prompt:
            self.response_box.append(f"[Vous] {prompt}")
            self.generate_model_response(prompt)

    def save_prompt(self):
        prompt = self.input_box.toPlainText().strip()
        if prompt:
            self.agent.save_to_memory(prompt, "Interaction sauvegard√©e manuellement.")
            self.response_box.append("[‚úî] Interaction sauvegard√©e.")

    def open_memory_window(self):
        mem_window = MemoryViewer(self.agent)
        mem_window.exec_()

    def closeEvent(self, event):
        self.voice_recognition_thread.stop()
        event.accept()
